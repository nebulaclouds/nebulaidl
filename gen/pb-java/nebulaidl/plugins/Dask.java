// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: nebulaidl/plugins/dask.proto

package nebulaidl.plugins;

public final class Dask {
  private Dask() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface DaskJobOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nebulaidl.plugins.DaskJob)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    boolean hasScheduler();
    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    nebulaidl.plugins.Dask.DaskScheduler getScheduler();
    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    nebulaidl.plugins.Dask.DaskSchedulerOrBuilder getSchedulerOrBuilder();

    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    boolean hasWorkers();
    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    nebulaidl.plugins.Dask.DaskWorkerGroup getWorkers();
    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder getWorkersOrBuilder();
  }
  /**
   * <pre>
   * Custom Proto for Dask Plugin.
   * </pre>
   *
   * Protobuf type {@code nebulaidl.plugins.DaskJob}
   */
  public  static final class DaskJob extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nebulaidl.plugins.DaskJob)
      DaskJobOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DaskJob.newBuilder() to construct.
    private DaskJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DaskJob() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DaskJob(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nebulaidl.plugins.Dask.DaskScheduler.Builder subBuilder = null;
              if (scheduler_ != null) {
                subBuilder = scheduler_.toBuilder();
              }
              scheduler_ = input.readMessage(nebulaidl.plugins.Dask.DaskScheduler.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(scheduler_);
                scheduler_ = subBuilder.buildPartial();
              }

              break;
            }
            case 18: {
              nebulaidl.plugins.Dask.DaskWorkerGroup.Builder subBuilder = null;
              if (workers_ != null) {
                subBuilder = workers_.toBuilder();
              }
              workers_ = input.readMessage(nebulaidl.plugins.Dask.DaskWorkerGroup.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(workers_);
                workers_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskJob_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nebulaidl.plugins.Dask.DaskJob.class, nebulaidl.plugins.Dask.DaskJob.Builder.class);
    }

    public static final int SCHEDULER_FIELD_NUMBER = 1;
    private nebulaidl.plugins.Dask.DaskScheduler scheduler_;
    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    public boolean hasScheduler() {
      return scheduler_ != null;
    }
    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    public nebulaidl.plugins.Dask.DaskScheduler getScheduler() {
      return scheduler_ == null ? nebulaidl.plugins.Dask.DaskScheduler.getDefaultInstance() : scheduler_;
    }
    /**
     * <pre>
     * Spec for the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
     */
    public nebulaidl.plugins.Dask.DaskSchedulerOrBuilder getSchedulerOrBuilder() {
      return getScheduler();
    }

    public static final int WORKERS_FIELD_NUMBER = 2;
    private nebulaidl.plugins.Dask.DaskWorkerGroup workers_;
    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    public boolean hasWorkers() {
      return workers_ != null;
    }
    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    public nebulaidl.plugins.Dask.DaskWorkerGroup getWorkers() {
      return workers_ == null ? nebulaidl.plugins.Dask.DaskWorkerGroup.getDefaultInstance() : workers_;
    }
    /**
     * <pre>
     * Spec of the default worker group.
     * </pre>
     *
     * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
     */
    public nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder getWorkersOrBuilder() {
      return getWorkers();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (scheduler_ != null) {
        output.writeMessage(1, getScheduler());
      }
      if (workers_ != null) {
        output.writeMessage(2, getWorkers());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (scheduler_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getScheduler());
      }
      if (workers_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getWorkers());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nebulaidl.plugins.Dask.DaskJob)) {
        return super.equals(obj);
      }
      nebulaidl.plugins.Dask.DaskJob other = (nebulaidl.plugins.Dask.DaskJob) obj;

      if (hasScheduler() != other.hasScheduler()) return false;
      if (hasScheduler()) {
        if (!getScheduler()
            .equals(other.getScheduler())) return false;
      }
      if (hasWorkers() != other.hasWorkers()) return false;
      if (hasWorkers()) {
        if (!getWorkers()
            .equals(other.getWorkers())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasScheduler()) {
        hash = (37 * hash) + SCHEDULER_FIELD_NUMBER;
        hash = (53 * hash) + getScheduler().hashCode();
      }
      if (hasWorkers()) {
        hash = (37 * hash) + WORKERS_FIELD_NUMBER;
        hash = (53 * hash) + getWorkers().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskJob parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nebulaidl.plugins.Dask.DaskJob prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Custom Proto for Dask Plugin.
     * </pre>
     *
     * Protobuf type {@code nebulaidl.plugins.DaskJob}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nebulaidl.plugins.DaskJob)
        nebulaidl.plugins.Dask.DaskJobOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskJob_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskJob_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nebulaidl.plugins.Dask.DaskJob.class, nebulaidl.plugins.Dask.DaskJob.Builder.class);
      }

      // Construct using nebulaidl.plugins.Dask.DaskJob.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (schedulerBuilder_ == null) {
          scheduler_ = null;
        } else {
          scheduler_ = null;
          schedulerBuilder_ = null;
        }
        if (workersBuilder_ == null) {
          workers_ = null;
        } else {
          workers_ = null;
          workersBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskJob_descriptor;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskJob getDefaultInstanceForType() {
        return nebulaidl.plugins.Dask.DaskJob.getDefaultInstance();
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskJob build() {
        nebulaidl.plugins.Dask.DaskJob result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskJob buildPartial() {
        nebulaidl.plugins.Dask.DaskJob result = new nebulaidl.plugins.Dask.DaskJob(this);
        if (schedulerBuilder_ == null) {
          result.scheduler_ = scheduler_;
        } else {
          result.scheduler_ = schedulerBuilder_.build();
        }
        if (workersBuilder_ == null) {
          result.workers_ = workers_;
        } else {
          result.workers_ = workersBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nebulaidl.plugins.Dask.DaskJob) {
          return mergeFrom((nebulaidl.plugins.Dask.DaskJob)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nebulaidl.plugins.Dask.DaskJob other) {
        if (other == nebulaidl.plugins.Dask.DaskJob.getDefaultInstance()) return this;
        if (other.hasScheduler()) {
          mergeScheduler(other.getScheduler());
        }
        if (other.hasWorkers()) {
          mergeWorkers(other.getWorkers());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nebulaidl.plugins.Dask.DaskJob parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nebulaidl.plugins.Dask.DaskJob) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nebulaidl.plugins.Dask.DaskScheduler scheduler_;
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.plugins.Dask.DaskScheduler, nebulaidl.plugins.Dask.DaskScheduler.Builder, nebulaidl.plugins.Dask.DaskSchedulerOrBuilder> schedulerBuilder_;
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public boolean hasScheduler() {
        return schedulerBuilder_ != null || scheduler_ != null;
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public nebulaidl.plugins.Dask.DaskScheduler getScheduler() {
        if (schedulerBuilder_ == null) {
          return scheduler_ == null ? nebulaidl.plugins.Dask.DaskScheduler.getDefaultInstance() : scheduler_;
        } else {
          return schedulerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public Builder setScheduler(nebulaidl.plugins.Dask.DaskScheduler value) {
        if (schedulerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scheduler_ = value;
          onChanged();
        } else {
          schedulerBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public Builder setScheduler(
          nebulaidl.plugins.Dask.DaskScheduler.Builder builderForValue) {
        if (schedulerBuilder_ == null) {
          scheduler_ = builderForValue.build();
          onChanged();
        } else {
          schedulerBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public Builder mergeScheduler(nebulaidl.plugins.Dask.DaskScheduler value) {
        if (schedulerBuilder_ == null) {
          if (scheduler_ != null) {
            scheduler_ =
              nebulaidl.plugins.Dask.DaskScheduler.newBuilder(scheduler_).mergeFrom(value).buildPartial();
          } else {
            scheduler_ = value;
          }
          onChanged();
        } else {
          schedulerBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public Builder clearScheduler() {
        if (schedulerBuilder_ == null) {
          scheduler_ = null;
          onChanged();
        } else {
          scheduler_ = null;
          schedulerBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public nebulaidl.plugins.Dask.DaskScheduler.Builder getSchedulerBuilder() {
        
        onChanged();
        return getSchedulerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      public nebulaidl.plugins.Dask.DaskSchedulerOrBuilder getSchedulerOrBuilder() {
        if (schedulerBuilder_ != null) {
          return schedulerBuilder_.getMessageOrBuilder();
        } else {
          return scheduler_ == null ?
              nebulaidl.plugins.Dask.DaskScheduler.getDefaultInstance() : scheduler_;
        }
      }
      /**
       * <pre>
       * Spec for the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskScheduler scheduler = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.plugins.Dask.DaskScheduler, nebulaidl.plugins.Dask.DaskScheduler.Builder, nebulaidl.plugins.Dask.DaskSchedulerOrBuilder>
          getSchedulerFieldBuilder() {
        if (schedulerBuilder_ == null) {
          schedulerBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nebulaidl.plugins.Dask.DaskScheduler, nebulaidl.plugins.Dask.DaskScheduler.Builder, nebulaidl.plugins.Dask.DaskSchedulerOrBuilder>(
                  getScheduler(),
                  getParentForChildren(),
                  isClean());
          scheduler_ = null;
        }
        return schedulerBuilder_;
      }

      private nebulaidl.plugins.Dask.DaskWorkerGroup workers_;
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.plugins.Dask.DaskWorkerGroup, nebulaidl.plugins.Dask.DaskWorkerGroup.Builder, nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder> workersBuilder_;
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public boolean hasWorkers() {
        return workersBuilder_ != null || workers_ != null;
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public nebulaidl.plugins.Dask.DaskWorkerGroup getWorkers() {
        if (workersBuilder_ == null) {
          return workers_ == null ? nebulaidl.plugins.Dask.DaskWorkerGroup.getDefaultInstance() : workers_;
        } else {
          return workersBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public Builder setWorkers(nebulaidl.plugins.Dask.DaskWorkerGroup value) {
        if (workersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          workers_ = value;
          onChanged();
        } else {
          workersBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public Builder setWorkers(
          nebulaidl.plugins.Dask.DaskWorkerGroup.Builder builderForValue) {
        if (workersBuilder_ == null) {
          workers_ = builderForValue.build();
          onChanged();
        } else {
          workersBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public Builder mergeWorkers(nebulaidl.plugins.Dask.DaskWorkerGroup value) {
        if (workersBuilder_ == null) {
          if (workers_ != null) {
            workers_ =
              nebulaidl.plugins.Dask.DaskWorkerGroup.newBuilder(workers_).mergeFrom(value).buildPartial();
          } else {
            workers_ = value;
          }
          onChanged();
        } else {
          workersBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public Builder clearWorkers() {
        if (workersBuilder_ == null) {
          workers_ = null;
          onChanged();
        } else {
          workers_ = null;
          workersBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public nebulaidl.plugins.Dask.DaskWorkerGroup.Builder getWorkersBuilder() {
        
        onChanged();
        return getWorkersFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      public nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder getWorkersOrBuilder() {
        if (workersBuilder_ != null) {
          return workersBuilder_.getMessageOrBuilder();
        } else {
          return workers_ == null ?
              nebulaidl.plugins.Dask.DaskWorkerGroup.getDefaultInstance() : workers_;
        }
      }
      /**
       * <pre>
       * Spec of the default worker group.
       * </pre>
       *
       * <code>.nebulaidl.plugins.DaskWorkerGroup workers = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.plugins.Dask.DaskWorkerGroup, nebulaidl.plugins.Dask.DaskWorkerGroup.Builder, nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder>
          getWorkersFieldBuilder() {
        if (workersBuilder_ == null) {
          workersBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nebulaidl.plugins.Dask.DaskWorkerGroup, nebulaidl.plugins.Dask.DaskWorkerGroup.Builder, nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder>(
                  getWorkers(),
                  getParentForChildren(),
                  isClean());
          workers_ = null;
        }
        return workersBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nebulaidl.plugins.DaskJob)
    }

    // @@protoc_insertion_point(class_scope:nebulaidl.plugins.DaskJob)
    private static final nebulaidl.plugins.Dask.DaskJob DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nebulaidl.plugins.Dask.DaskJob();
    }

    public static nebulaidl.plugins.Dask.DaskJob getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<DaskJob>
        PARSER = new com.google.protobuf.AbstractParser<DaskJob>() {
      @java.lang.Override
      public DaskJob parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DaskJob(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DaskJob> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DaskJob> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nebulaidl.plugins.Dask.DaskJob getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DaskSchedulerOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nebulaidl.plugins.DaskScheduler)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Optional image to use. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 1;</code>
     */
    java.lang.String getImage();
    /**
     * <pre>
     * Optional image to use. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 1;</code>
     */
    com.google.protobuf.ByteString
        getImageBytes();

    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    boolean hasResources();
    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    nebulaidl.core.Tasks.Resources getResources();
    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder();
  }
  /**
   * <pre>
   * Specification for the scheduler pod.
   * </pre>
   *
   * Protobuf type {@code nebulaidl.plugins.DaskScheduler}
   */
  public  static final class DaskScheduler extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nebulaidl.plugins.DaskScheduler)
      DaskSchedulerOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DaskScheduler.newBuilder() to construct.
    private DaskScheduler(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DaskScheduler() {
      image_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DaskScheduler(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              image_ = s;
              break;
            }
            case 18: {
              nebulaidl.core.Tasks.Resources.Builder subBuilder = null;
              if (resources_ != null) {
                subBuilder = resources_.toBuilder();
              }
              resources_ = input.readMessage(nebulaidl.core.Tasks.Resources.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resources_);
                resources_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskScheduler_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskScheduler_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nebulaidl.plugins.Dask.DaskScheduler.class, nebulaidl.plugins.Dask.DaskScheduler.Builder.class);
    }

    public static final int IMAGE_FIELD_NUMBER = 1;
    private volatile java.lang.Object image_;
    /**
     * <pre>
     * Optional image to use. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 1;</code>
     */
    public java.lang.String getImage() {
      java.lang.Object ref = image_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        image_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional image to use. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 1;</code>
     */
    public com.google.protobuf.ByteString
        getImageBytes() {
      java.lang.Object ref = image_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        image_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RESOURCES_FIELD_NUMBER = 2;
    private nebulaidl.core.Tasks.Resources resources_;
    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    public boolean hasResources() {
      return resources_ != null;
    }
    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    public nebulaidl.core.Tasks.Resources getResources() {
      return resources_ == null ? nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
    }
    /**
     * <pre>
     * Resources assigned to the scheduler pod.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 2;</code>
     */
    public nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder() {
      return getResources();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getImageBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, image_);
      }
      if (resources_ != null) {
        output.writeMessage(2, getResources());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getImageBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, image_);
      }
      if (resources_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getResources());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nebulaidl.plugins.Dask.DaskScheduler)) {
        return super.equals(obj);
      }
      nebulaidl.plugins.Dask.DaskScheduler other = (nebulaidl.plugins.Dask.DaskScheduler) obj;

      if (!getImage()
          .equals(other.getImage())) return false;
      if (hasResources() != other.hasResources()) return false;
      if (hasResources()) {
        if (!getResources()
            .equals(other.getResources())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + IMAGE_FIELD_NUMBER;
      hash = (53 * hash) + getImage().hashCode();
      if (hasResources()) {
        hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getResources().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskScheduler parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nebulaidl.plugins.Dask.DaskScheduler prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Specification for the scheduler pod.
     * </pre>
     *
     * Protobuf type {@code nebulaidl.plugins.DaskScheduler}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nebulaidl.plugins.DaskScheduler)
        nebulaidl.plugins.Dask.DaskSchedulerOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskScheduler_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskScheduler_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nebulaidl.plugins.Dask.DaskScheduler.class, nebulaidl.plugins.Dask.DaskScheduler.Builder.class);
      }

      // Construct using nebulaidl.plugins.Dask.DaskScheduler.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        image_ = "";

        if (resourcesBuilder_ == null) {
          resources_ = null;
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskScheduler_descriptor;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskScheduler getDefaultInstanceForType() {
        return nebulaidl.plugins.Dask.DaskScheduler.getDefaultInstance();
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskScheduler build() {
        nebulaidl.plugins.Dask.DaskScheduler result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskScheduler buildPartial() {
        nebulaidl.plugins.Dask.DaskScheduler result = new nebulaidl.plugins.Dask.DaskScheduler(this);
        result.image_ = image_;
        if (resourcesBuilder_ == null) {
          result.resources_ = resources_;
        } else {
          result.resources_ = resourcesBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nebulaidl.plugins.Dask.DaskScheduler) {
          return mergeFrom((nebulaidl.plugins.Dask.DaskScheduler)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nebulaidl.plugins.Dask.DaskScheduler other) {
        if (other == nebulaidl.plugins.Dask.DaskScheduler.getDefaultInstance()) return this;
        if (!other.getImage().isEmpty()) {
          image_ = other.image_;
          onChanged();
        }
        if (other.hasResources()) {
          mergeResources(other.getResources());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nebulaidl.plugins.Dask.DaskScheduler parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nebulaidl.plugins.Dask.DaskScheduler) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object image_ = "";
      /**
       * <pre>
       * Optional image to use. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 1;</code>
       */
      public java.lang.String getImage() {
        java.lang.Object ref = image_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          image_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional image to use. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 1;</code>
       */
      public com.google.protobuf.ByteString
          getImageBytes() {
        java.lang.Object ref = image_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          image_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional image to use. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 1;</code>
       */
      public Builder setImage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        image_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional image to use. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 1;</code>
       */
      public Builder clearImage() {
        
        image_ = getDefaultInstance().getImage();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional image to use. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 1;</code>
       */
      public Builder setImageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        image_ = value;
        onChanged();
        return this;
      }

      private nebulaidl.core.Tasks.Resources resources_;
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder> resourcesBuilder_;
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public boolean hasResources() {
        return resourcesBuilder_ != null || resources_ != null;
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public nebulaidl.core.Tasks.Resources getResources() {
        if (resourcesBuilder_ == null) {
          return resources_ == null ? nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
        } else {
          return resourcesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public Builder setResources(nebulaidl.core.Tasks.Resources value) {
        if (resourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resources_ = value;
          onChanged();
        } else {
          resourcesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public Builder setResources(
          nebulaidl.core.Tasks.Resources.Builder builderForValue) {
        if (resourcesBuilder_ == null) {
          resources_ = builderForValue.build();
          onChanged();
        } else {
          resourcesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public Builder mergeResources(nebulaidl.core.Tasks.Resources value) {
        if (resourcesBuilder_ == null) {
          if (resources_ != null) {
            resources_ =
              nebulaidl.core.Tasks.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
          } else {
            resources_ = value;
          }
          onChanged();
        } else {
          resourcesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public Builder clearResources() {
        if (resourcesBuilder_ == null) {
          resources_ = null;
          onChanged();
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public nebulaidl.core.Tasks.Resources.Builder getResourcesBuilder() {
        
        onChanged();
        return getResourcesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      public nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder() {
        if (resourcesBuilder_ != null) {
          return resourcesBuilder_.getMessageOrBuilder();
        } else {
          return resources_ == null ?
              nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
        }
      }
      /**
       * <pre>
       * Resources assigned to the scheduler pod.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder>
          getResourcesFieldBuilder() {
        if (resourcesBuilder_ == null) {
          resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder>(
                  getResources(),
                  getParentForChildren(),
                  isClean());
          resources_ = null;
        }
        return resourcesBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nebulaidl.plugins.DaskScheduler)
    }

    // @@protoc_insertion_point(class_scope:nebulaidl.plugins.DaskScheduler)
    private static final nebulaidl.plugins.Dask.DaskScheduler DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nebulaidl.plugins.Dask.DaskScheduler();
    }

    public static nebulaidl.plugins.Dask.DaskScheduler getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<DaskScheduler>
        PARSER = new com.google.protobuf.AbstractParser<DaskScheduler>() {
      @java.lang.Override
      public DaskScheduler parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DaskScheduler(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DaskScheduler> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DaskScheduler> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nebulaidl.plugins.Dask.DaskScheduler getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DaskWorkerGroupOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nebulaidl.plugins.DaskWorkerGroup)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Number of workers in the group.
     * </pre>
     *
     * <code>uint32 number_of_workers = 1;</code>
     */
    int getNumberOfWorkers();

    /**
     * <pre>
     * Optional image to use for the pods of the worker group. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 2;</code>
     */
    java.lang.String getImage();
    /**
     * <pre>
     * Optional image to use for the pods of the worker group. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 2;</code>
     */
    com.google.protobuf.ByteString
        getImageBytes();

    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    boolean hasResources();
    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    nebulaidl.core.Tasks.Resources getResources();
    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder();
  }
  /**
   * Protobuf type {@code nebulaidl.plugins.DaskWorkerGroup}
   */
  public  static final class DaskWorkerGroup extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nebulaidl.plugins.DaskWorkerGroup)
      DaskWorkerGroupOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DaskWorkerGroup.newBuilder() to construct.
    private DaskWorkerGroup(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DaskWorkerGroup() {
      image_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DaskWorkerGroup(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {

              numberOfWorkers_ = input.readUInt32();
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              image_ = s;
              break;
            }
            case 26: {
              nebulaidl.core.Tasks.Resources.Builder subBuilder = null;
              if (resources_ != null) {
                subBuilder = resources_.toBuilder();
              }
              resources_ = input.readMessage(nebulaidl.core.Tasks.Resources.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resources_);
                resources_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskWorkerGroup_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nebulaidl.plugins.Dask.DaskWorkerGroup.class, nebulaidl.plugins.Dask.DaskWorkerGroup.Builder.class);
    }

    public static final int NUMBER_OF_WORKERS_FIELD_NUMBER = 1;
    private int numberOfWorkers_;
    /**
     * <pre>
     * Number of workers in the group.
     * </pre>
     *
     * <code>uint32 number_of_workers = 1;</code>
     */
    public int getNumberOfWorkers() {
      return numberOfWorkers_;
    }

    public static final int IMAGE_FIELD_NUMBER = 2;
    private volatile java.lang.Object image_;
    /**
     * <pre>
     * Optional image to use for the pods of the worker group. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 2;</code>
     */
    public java.lang.String getImage() {
      java.lang.Object ref = image_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        image_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional image to use for the pods of the worker group. If unset, will use the default image.
     * </pre>
     *
     * <code>string image = 2;</code>
     */
    public com.google.protobuf.ByteString
        getImageBytes() {
      java.lang.Object ref = image_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        image_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RESOURCES_FIELD_NUMBER = 3;
    private nebulaidl.core.Tasks.Resources resources_;
    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    public boolean hasResources() {
      return resources_ != null;
    }
    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    public nebulaidl.core.Tasks.Resources getResources() {
      return resources_ == null ? nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
    }
    /**
     * <pre>
     * Resources assigned to the all pods of the worker group.
     * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
     * it is advised to only set limits. If requests are not explicitly set, the plugin will make
     * sure to set requests==limits.
     * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
     * </pre>
     *
     * <code>.nebulaidl.core.Resources resources = 3;</code>
     */
    public nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder() {
      return getResources();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (numberOfWorkers_ != 0) {
        output.writeUInt32(1, numberOfWorkers_);
      }
      if (!getImageBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, image_);
      }
      if (resources_ != null) {
        output.writeMessage(3, getResources());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (numberOfWorkers_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, numberOfWorkers_);
      }
      if (!getImageBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, image_);
      }
      if (resources_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getResources());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nebulaidl.plugins.Dask.DaskWorkerGroup)) {
        return super.equals(obj);
      }
      nebulaidl.plugins.Dask.DaskWorkerGroup other = (nebulaidl.plugins.Dask.DaskWorkerGroup) obj;

      if (getNumberOfWorkers()
          != other.getNumberOfWorkers()) return false;
      if (!getImage()
          .equals(other.getImage())) return false;
      if (hasResources() != other.hasResources()) return false;
      if (hasResources()) {
        if (!getResources()
            .equals(other.getResources())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NUMBER_OF_WORKERS_FIELD_NUMBER;
      hash = (53 * hash) + getNumberOfWorkers();
      hash = (37 * hash) + IMAGE_FIELD_NUMBER;
      hash = (53 * hash) + getImage().hashCode();
      if (hasResources()) {
        hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getResources().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nebulaidl.plugins.Dask.DaskWorkerGroup parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nebulaidl.plugins.Dask.DaskWorkerGroup prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code nebulaidl.plugins.DaskWorkerGroup}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nebulaidl.plugins.DaskWorkerGroup)
        nebulaidl.plugins.Dask.DaskWorkerGroupOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskWorkerGroup_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nebulaidl.plugins.Dask.DaskWorkerGroup.class, nebulaidl.plugins.Dask.DaskWorkerGroup.Builder.class);
      }

      // Construct using nebulaidl.plugins.Dask.DaskWorkerGroup.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        numberOfWorkers_ = 0;

        image_ = "";

        if (resourcesBuilder_ == null) {
          resources_ = null;
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nebulaidl.plugins.Dask.internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskWorkerGroup getDefaultInstanceForType() {
        return nebulaidl.plugins.Dask.DaskWorkerGroup.getDefaultInstance();
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskWorkerGroup build() {
        nebulaidl.plugins.Dask.DaskWorkerGroup result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nebulaidl.plugins.Dask.DaskWorkerGroup buildPartial() {
        nebulaidl.plugins.Dask.DaskWorkerGroup result = new nebulaidl.plugins.Dask.DaskWorkerGroup(this);
        result.numberOfWorkers_ = numberOfWorkers_;
        result.image_ = image_;
        if (resourcesBuilder_ == null) {
          result.resources_ = resources_;
        } else {
          result.resources_ = resourcesBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nebulaidl.plugins.Dask.DaskWorkerGroup) {
          return mergeFrom((nebulaidl.plugins.Dask.DaskWorkerGroup)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nebulaidl.plugins.Dask.DaskWorkerGroup other) {
        if (other == nebulaidl.plugins.Dask.DaskWorkerGroup.getDefaultInstance()) return this;
        if (other.getNumberOfWorkers() != 0) {
          setNumberOfWorkers(other.getNumberOfWorkers());
        }
        if (!other.getImage().isEmpty()) {
          image_ = other.image_;
          onChanged();
        }
        if (other.hasResources()) {
          mergeResources(other.getResources());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nebulaidl.plugins.Dask.DaskWorkerGroup parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nebulaidl.plugins.Dask.DaskWorkerGroup) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int numberOfWorkers_ ;
      /**
       * <pre>
       * Number of workers in the group.
       * </pre>
       *
       * <code>uint32 number_of_workers = 1;</code>
       */
      public int getNumberOfWorkers() {
        return numberOfWorkers_;
      }
      /**
       * <pre>
       * Number of workers in the group.
       * </pre>
       *
       * <code>uint32 number_of_workers = 1;</code>
       */
      public Builder setNumberOfWorkers(int value) {
        
        numberOfWorkers_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Number of workers in the group.
       * </pre>
       *
       * <code>uint32 number_of_workers = 1;</code>
       */
      public Builder clearNumberOfWorkers() {
        
        numberOfWorkers_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object image_ = "";
      /**
       * <pre>
       * Optional image to use for the pods of the worker group. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 2;</code>
       */
      public java.lang.String getImage() {
        java.lang.Object ref = image_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          image_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional image to use for the pods of the worker group. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 2;</code>
       */
      public com.google.protobuf.ByteString
          getImageBytes() {
        java.lang.Object ref = image_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          image_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional image to use for the pods of the worker group. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 2;</code>
       */
      public Builder setImage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        image_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional image to use for the pods of the worker group. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 2;</code>
       */
      public Builder clearImage() {
        
        image_ = getDefaultInstance().getImage();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional image to use for the pods of the worker group. If unset, will use the default image.
       * </pre>
       *
       * <code>string image = 2;</code>
       */
      public Builder setImageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        image_ = value;
        onChanged();
        return this;
      }

      private nebulaidl.core.Tasks.Resources resources_;
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder> resourcesBuilder_;
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public boolean hasResources() {
        return resourcesBuilder_ != null || resources_ != null;
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public nebulaidl.core.Tasks.Resources getResources() {
        if (resourcesBuilder_ == null) {
          return resources_ == null ? nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
        } else {
          return resourcesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public Builder setResources(nebulaidl.core.Tasks.Resources value) {
        if (resourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resources_ = value;
          onChanged();
        } else {
          resourcesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public Builder setResources(
          nebulaidl.core.Tasks.Resources.Builder builderForValue) {
        if (resourcesBuilder_ == null) {
          resources_ = builderForValue.build();
          onChanged();
        } else {
          resourcesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public Builder mergeResources(nebulaidl.core.Tasks.Resources value) {
        if (resourcesBuilder_ == null) {
          if (resources_ != null) {
            resources_ =
              nebulaidl.core.Tasks.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
          } else {
            resources_ = value;
          }
          onChanged();
        } else {
          resourcesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public Builder clearResources() {
        if (resourcesBuilder_ == null) {
          resources_ = null;
          onChanged();
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public nebulaidl.core.Tasks.Resources.Builder getResourcesBuilder() {
        
        onChanged();
        return getResourcesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      public nebulaidl.core.Tasks.ResourcesOrBuilder getResourcesOrBuilder() {
        if (resourcesBuilder_ != null) {
          return resourcesBuilder_.getMessageOrBuilder();
        } else {
          return resources_ == null ?
              nebulaidl.core.Tasks.Resources.getDefaultInstance() : resources_;
        }
      }
      /**
       * <pre>
       * Resources assigned to the all pods of the worker group.
       * As per https://kubernetes.dask.org/en/latest/kubecluster.html?highlight=limit#best-practices 
       * it is advised to only set limits. If requests are not explicitly set, the plugin will make
       * sure to set requests==limits.
       * The plugin sets ` --memory-limit` as well as `--nthreads` for the workers according to the limit.
       * </pre>
       *
       * <code>.nebulaidl.core.Resources resources = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder>
          getResourcesFieldBuilder() {
        if (resourcesBuilder_ == null) {
          resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nebulaidl.core.Tasks.Resources, nebulaidl.core.Tasks.Resources.Builder, nebulaidl.core.Tasks.ResourcesOrBuilder>(
                  getResources(),
                  getParentForChildren(),
                  isClean());
          resources_ = null;
        }
        return resourcesBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nebulaidl.plugins.DaskWorkerGroup)
    }

    // @@protoc_insertion_point(class_scope:nebulaidl.plugins.DaskWorkerGroup)
    private static final nebulaidl.plugins.Dask.DaskWorkerGroup DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nebulaidl.plugins.Dask.DaskWorkerGroup();
    }

    public static nebulaidl.plugins.Dask.DaskWorkerGroup getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<DaskWorkerGroup>
        PARSER = new com.google.protobuf.AbstractParser<DaskWorkerGroup>() {
      @java.lang.Override
      public DaskWorkerGroup parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DaskWorkerGroup(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DaskWorkerGroup> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DaskWorkerGroup> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nebulaidl.plugins.Dask.DaskWorkerGroup getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nebulaidl_plugins_DaskJob_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nebulaidl_plugins_DaskJob_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nebulaidl_plugins_DaskScheduler_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nebulaidl_plugins_DaskScheduler_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nebulaidl_plugins_DaskWorkerGroup_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\033nebulaidl/plugins/dask.proto\022\020nebulaidl." +
      "plugins\032\031nebulaidl/core/tasks.proto\"q\n\007Da" +
      "skJob\0222\n\tscheduler\030\001 \001(\0132\037.nebulaidl.plug" +
      "ins.DaskScheduler\0222\n\007workers\030\002 \001(\0132!.fly" +
      "teidl.plugins.DaskWorkerGroup\"K\n\rDaskSch" +
      "eduler\022\r\n\005image\030\001 \001(\t\022+\n\tresources\030\002 \001(\013" +
      "2\030.nebulaidl.core.Resources\"h\n\017DaskWorker" +
      "Group\022\031\n\021number_of_workers\030\001 \001(\r\022\r\n\005imag" +
      "e\030\002 \001(\t\022+\n\tresources\030\003 \001(\0132\030.nebulaidl.co" +
      "re.ResourcesB9Z7github.com/nebulaclouds/flyt" +
      "eidl/gen/pb-go/nebulaidl/pluginsb\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          nebulaidl.core.Tasks.getDescriptor(),
        }, assigner);
    internal_static_nebulaidl_plugins_DaskJob_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_nebulaidl_plugins_DaskJob_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nebulaidl_plugins_DaskJob_descriptor,
        new java.lang.String[] { "Scheduler", "Workers", });
    internal_static_nebulaidl_plugins_DaskScheduler_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_nebulaidl_plugins_DaskScheduler_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nebulaidl_plugins_DaskScheduler_descriptor,
        new java.lang.String[] { "Image", "Resources", });
    internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_nebulaidl_plugins_DaskWorkerGroup_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nebulaidl_plugins_DaskWorkerGroup_descriptor,
        new java.lang.String[] { "NumberOfWorkers", "Image", "Resources", });
    nebulaidl.core.Tasks.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
